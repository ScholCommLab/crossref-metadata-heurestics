{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c67319b3",
   "metadata": {},
   "source": [
    "# Labeling the Data\n",
    "We identified many issues in Phase 1. Now we will go through and programatically label the records in this sample if they contain some of those issues.\n",
    "## Author Problems\n",
    "We'll start off by investigating the *author* field. This is an area that was found to have a number of potentially high priority issues as it pertains to social and political matters, as well as a field that has seen the some of the most pervasive issues in standardization. \n",
    "\n",
    "Start by importing the packages we'll need, setting up our directories, and loading in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ca09ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #Creating dataframe and manipulating data\n",
    "from bs4 import BeautifulSoup as bs # for cleaning xml tags\n",
    "import re #regular expressions used for detection of initials\n",
    "import langid #For language detection\n",
    "from nltk.tokenize import sent_tokenize #Tokenizing abstracts during language detection\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f936855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>indexed</th>\n",
       "      <th>publisher</th>\n",
       "      <th>content-domain</th>\n",
       "      <th>short-container-title</th>\n",
       "      <th>DOI</th>\n",
       "      <th>created</th>\n",
       "      <th>is-referenced-by-count</th>\n",
       "      <th>title</th>\n",
       "      <th>prefix</th>\n",
       "      <th>volume</th>\n",
       "      <th>author</th>\n",
       "      <th>member</th>\n",
       "      <th>reference</th>\n",
       "      <th>container-title</th>\n",
       "      <th>language</th>\n",
       "      <th>link</th>\n",
       "      <th>deposited</th>\n",
       "      <th>resource</th>\n",
       "      <th>issued</th>\n",
       "      <th>references-count</th>\n",
       "      <th>journal-issue</th>\n",
       "      <th>URL</th>\n",
       "      <th>subject</th>\n",
       "      <th>alternative-id</th>\n",
       "      <th>assertion</th>\n",
       "      <th>abstract</th>\n",
       "      <th>original-title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>editor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-07</td>\n",
       "      <td>Wiley</td>\n",
       "      <td>{'domain': [], 'crossmark-restriction': False}</td>\n",
       "      <td>Syst. Dyn. Rev.</td>\n",
       "      <td>10.1002/(sici)1099-1727(200021)16:1&lt;27::aid-sd...</td>\n",
       "      <td>2002-09-10</td>\n",
       "      <td>57</td>\n",
       "      <td>The validation of commercial system dynamics m...</td>\n",
       "      <td>10.1002</td>\n",
       "      <td>16</td>\n",
       "      <td>[{'given': 'Geoff', 'family': 'Coyle', 'sequen...</td>\n",
       "      <td>311.0</td>\n",
       "      <td>[{'key': '10.1002/(SICI)1099-1727(200021)16:1&lt;...</td>\n",
       "      <td>System Dynamics Review</td>\n",
       "      <td>en</td>\n",
       "      <td>[{'URL': 'https://api.wiley.com/onlinelibrary/...</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>{'primary': {'URL': 'https://onlinelibrary.wil...</td>\n",
       "      <td>{'date-parts': [[2000]]}</td>\n",
       "      <td>14</td>\n",
       "      <td>{'issue': '1', 'published-print': {'date-parts...</td>\n",
       "      <td>http://dx.doi.org/10.1002/(sici)1099-1727(2000...</td>\n",
       "      <td>['Management of Technology and Innovation', 'S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-03-29</td>\n",
       "      <td>Springer Science and Business Media LLC</td>\n",
       "      <td>{'domain': [], 'crossmark-restriction': False}</td>\n",
       "      <td>MTB</td>\n",
       "      <td>10.1007/bf02653972</td>\n",
       "      <td>2007-07-17</td>\n",
       "      <td>20</td>\n",
       "      <td>Effect of system geometry on the leaching beha...</td>\n",
       "      <td>10.1007</td>\n",
       "      <td>10</td>\n",
       "      <td>[{'given': 'C.', 'family': 'Vu', 'sequence': '...</td>\n",
       "      <td>297.0</td>\n",
       "      <td>[{'key': 'BF02653972_CR1', 'volume-title': 'Ph...</td>\n",
       "      <td>Metallurgical Transactions B</td>\n",
       "      <td>en</td>\n",
       "      <td>[{'URL': 'http://link.springer.com/content/pdf...</td>\n",
       "      <td>2019-05-20</td>\n",
       "      <td>{'primary': {'URL': 'http://link.springer.com/...</td>\n",
       "      <td>{'date-parts': [[1979, 3]]}</td>\n",
       "      <td>12</td>\n",
       "      <td>{'issue': '1', 'published-print': {'date-parts...</td>\n",
       "      <td>http://dx.doi.org/10.1007/bf02653972</td>\n",
       "      <td>['Materials Chemistry', 'Metals and Alloys', '...</td>\n",
       "      <td>['BF02653972']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>Wiley</td>\n",
       "      <td>{'domain': [], 'crossmark-restriction': False}</td>\n",
       "      <td>RECIEL</td>\n",
       "      <td>10.1111/reel.12221</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>2</td>\n",
       "      <td>The international law on transboundary haze po...</td>\n",
       "      <td>10.1111</td>\n",
       "      <td>26</td>\n",
       "      <td>[{'given': 'Shawkat', 'family': 'Alam', 'seque...</td>\n",
       "      <td>311.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Review of European, Comparative &amp;amp; Internat...</td>\n",
       "      <td>en</td>\n",
       "      <td>[{'URL': 'https://api.wiley.com/onlinelibrary/...</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>{'primary': {'URL': 'http://doi.wiley.com/10.1...</td>\n",
       "      <td>{'date-parts': [[2017, 11]]}</td>\n",
       "      <td>0</td>\n",
       "      <td>{'issue': '3', 'published-print': {'date-parts...</td>\n",
       "      <td>http://dx.doi.org/10.1111/reel.12221</td>\n",
       "      <td>['Law', 'Management, Monitoring, Policy and La...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-04-03</td>\n",
       "      <td>Crop Science Society of Japan</td>\n",
       "      <td>{'domain': [], 'crossmark-restriction': False}</td>\n",
       "      <td>Japanese journal of crop science', 'Jpn. J. Cr...</td>\n",
       "      <td>10.1626/jcs.20.219</td>\n",
       "      <td>2011-09-20</td>\n",
       "      <td>0</td>\n",
       "      <td>Studies on the influence of pruning on the veg...</td>\n",
       "      <td>10.1626</td>\n",
       "      <td>20</td>\n",
       "      <td>[{'given': 'C.', 'family': 'TSUDA', 'sequence'...</td>\n",
       "      <td>632.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Japanese Journal of Crop Science</td>\n",
       "      <td>en</td>\n",
       "      <td>[{'URL': 'http://www.jstage.jst.go.jp/article/...</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>{'primary': {'URL': 'http://www.jstage.jst.go....</td>\n",
       "      <td>{'date-parts': [[1951]]}</td>\n",
       "      <td>0</td>\n",
       "      <td>{'issue': '1-2', 'published-print': {'date-par...</td>\n",
       "      <td>http://dx.doi.org/10.1626/jcs.20.219</td>\n",
       "      <td>['Genetics', 'Agronomy and Crop Science', 'Foo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>Elsevier BV</td>\n",
       "      <td>{'domain': ['clinicalkey.fr', 'elsevier.com', ...</td>\n",
       "      <td>Revue de Pneumologie Clinique</td>\n",
       "      <td>10.1016/j.pneumo.2018.09.002</td>\n",
       "      <td>2018-10-10</td>\n",
       "      <td>0</td>\n",
       "      <td>Le tabagisme et l’aide à l’arrêt du tabac des ...</td>\n",
       "      <td>10.1016</td>\n",
       "      <td>74</td>\n",
       "      <td>[{'given': 'J.', 'family': 'Perriot', 'sequenc...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>[{'key': '10.1016/j.pneumo.2018.09.002_bib0305...</td>\n",
       "      <td>Revue de Pneumologie Clinique</td>\n",
       "      <td>fr</td>\n",
       "      <td>[{'URL': 'https://api.elsevier.com/content/art...</td>\n",
       "      <td>2019-10-26</td>\n",
       "      <td>{'primary': {'URL': 'https://linkinghub.elsevi...</td>\n",
       "      <td>{'date-parts': [[2018, 12]]}</td>\n",
       "      <td>60</td>\n",
       "      <td>{'issue': '6', 'published-print': {'date-parts...</td>\n",
       "      <td>http://dx.doi.org/10.1016/j.pneumo.2018.09.002</td>\n",
       "      <td>['Pulmonary and Respiratory Medicine']</td>\n",
       "      <td>['S0761841718301792']</td>\n",
       "      <td>[{'value': 'Elsevier', 'name': 'publisher', 'l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index    indexed  ... subtitle editor\n",
       "0      0 2022-10-07  ...      NaN    NaN\n",
       "1      1 2022-03-29  ...      NaN    NaN\n",
       "2      2 2022-03-30  ...      NaN    NaN\n",
       "3      3 2022-04-03  ...      NaN    NaN\n",
       "4      4 2022-03-31  ...      NaN    NaN\n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Directory\n",
    "data_dir = Path('../data')\n",
    "input_dir = data_dir / 'input'\n",
    "output_dir = data_dir / 'output'\n",
    "# Loading in dataset\n",
    "df = pd.read_csv(input_dir / 'cleaned_data.csv', parse_dates=['indexed', 'created', 'deposited'], infer_datetime_format=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcabccf1",
   "metadata": {},
   "source": [
    "## Problem Detection Functions and Data Labeling\n",
    "### Author Sequence\n",
    "Our first function will be checking the *sequence* sub-field within the *author* field. This is the field wherein authors are either listed as 'first' or 'addtional'. This function sets up a counter then iterates through the author list of a record to check what the noted sequence is for each author.\n",
    "\n",
    "The `try` block filters out records that have no authors listed. After that we begin to iterate through each author within a given record.\n",
    "\n",
    "`If 'name' in author.keys():` is used to filter out institutions listed as authors as using the 'name' key is often how an institution is presented as an author within the metadata record. The code within the `if` block simply says if there's an institution as an author and they are the only author listed, increase the counter to 1, then the code will continue down to the `return` statements where **0** will be returned as technically there is not an issue with sequence in that record.\n",
    "\n",
    "`else: if author['sequence'] == 'first'` block is where the bulk of the counting activity will happen. Up until this point we are mostly filtering out instances that don't apply to the problem at hand. Simply, the function will count how many authors are labled as 'first'. Once all authors of a record have been parsed, we go to the `return` statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc852d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_checker(authorList):\n",
    "    counter = 0 \n",
    "    try: \n",
    "        for author in authorList:\n",
    "                if 'name' in author.keys():\n",
    "                    if len(authorList) == 1:\n",
    "                        counter +=1\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    if author['sequence'] == 'first':\n",
    "                        counter +=1\n",
    "                    else:\n",
    "                        continue\n",
    "        if counter == 0:\n",
    "            return 1 #no first author\n",
    "        elif counter > 1:\n",
    "            return 1 #multiple first authors\n",
    "        else:\n",
    "            return 0 #no issue\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3b5012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'author' and 'subject' columns need to be evaluated and formated before parsing,\n",
    "# otherwise they are treated as strings instead of dicts/lists.\n",
    "import ast\n",
    "def reformat_col(record):\n",
    "    try:\n",
    "        formed = ast.literal_eval(record)\n",
    "        return formed\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "cols_to_reformat = ['author', 'subject']\n",
    "for col in cols_to_reformat:\n",
    "    df[col] = df[col].apply(lambda x: reformat_col(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ace653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['author_sequence'] = df.author.map(lambda x: sequence_checker(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88092aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0472364035485202"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_with_AuSeq = df.loc[(df.author_sequence == 1)] #creating a df with only the cords with these errors\n",
    "prevalence_AuSeq = ((len(records_with_AuSeq))/(len(df.author_sequence))) * 100\n",
    "prevalence_AuSeq #returning a percent of the total number of records with this particular issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8932d2",
   "metadata": {},
   "source": [
    "### Author Initials\n",
    "This function will utilize regular expressions for detecting the use of initials. Specifically, we are looking for when initials are used in totality, that is to say a record with \"Marianne E.\" will not be flagged, whereas a record with \"D.\" will.\n",
    "\n",
    "We look in both the 'given' and the 'family' sub-fields as this use of initials has been found in both sub-fields previously. \n",
    "\n",
    "The flow of the function operates similarly to the `sequence_checker`, we filter out records with `null` authors in the first `try` statement, followed by iteration through the author list, then another `try` statement where we filter out institutions as authors.\n",
    "\n",
    "The regular expressions can be broken into two conditions: `^(?:[A-Z]\\W{,3}\\s?){,3}` and `(?:[^\\W\\d_.]\\W){1,2}\\B` which are seperated by `|`. This is because each of those expressions are looking for initials, the former is looking in ASCII characters, whereas the latter s looking for the pattern in non-Latin characters.\n",
    "\n",
    "`if detector != None or len(author['given']) == 1` insures that all initialized names are caught and then returned with the appropriate label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72c17b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def author_initials_checker(authorList):\n",
    "    try: #Filter for no authors\n",
    "        for author in authorList: #iterating through author array\n",
    "            try: #filter for institutions as authors\n",
    "                detector = re.match(r\"^(?:[A-Z]\\W{,3}\\s?){,3}$|(?:[^\\W\\d_.]\\W){1,2}\\B$\", author['given'].capitalize()) #checking for initials in given\n",
    "                if detector != None or len(author['given']) == 1:\n",
    "                    return 1 #initials used\n",
    "                else:\n",
    "                    family_detector = detector = re.match(r\"^(?:[A-Z]\\W{,3}\\s?){,3}$|(?:[^\\W\\d_.]\\W){1,2}\\B$\", author['family'].capitalize()) #initials in family\n",
    "                    if family_detector != None or len(author['family']) == 1:\n",
    "                        return 1 #initials used\n",
    "                    else:\n",
    "                        pass\n",
    "            except:\n",
    "                pass\n",
    "                        \n",
    "    except:\n",
    "        return None\n",
    "    return 0 #no issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae07676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['author_initials'] = df.author.map(lambda x: author_initials_checker(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd6210bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.118287365696965"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_with_initials = df.loc[df.author_initials == 1]\n",
    "prevalence_author_initials = ((len(records_with_initials))/(len(df.author_initials))) * 100\n",
    "prevalence_author_initials # percentage of records with this specific issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62251bd9",
   "metadata": {},
   "source": [
    "### Institutions as Authors\n",
    "This function will address instances in which institutions are recorded as authors.\n",
    "\n",
    "`try:` will filter out records with `null` authors. Then we have the `institutions_present` list that looks for the telltale sign of an institution, the 'name' sub-field. \n",
    "\n",
    "If the list is populated with any authors, then the appropriate label signalling an institution will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4310069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def institution_as_author(authorList):\n",
    "    try:\n",
    "        institutions_present = [author for author in authorList if 'name' in author.keys()]\n",
    "        if len(institutions_present) > 0:\n",
    "            return 1 #institution as author\n",
    "        else:\n",
    "            return 0 #no issue\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2077ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['author_institutions'] = df.author.map(lambda x: institution_as_author(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94e2d012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6806130360793081"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_with_AuIns = df.loc[df.author_institutions == 1]\n",
    "prevalence_AuIns = ((len(records_with_AuIns))/(len(df.author_institutions))) * 100\n",
    "prevalence_AuIns #percentage of records with this specific issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691f68b8",
   "metadata": {},
   "source": [
    "### Non-Latin Characters\n",
    "\n",
    "This function detects the use of non-latin character sets. Particularly we are interested in practices of romanization and when it occurs: which journals, are the *language* fields present and accurate, and so on. \n",
    "\n",
    "First, we have to identify which records are using non-latin characters.\n",
    "\n",
    "This is split into two different functions. The first utilizes a regular expression `(?:[^ı́\\x00-\\xff])` to detect any characters not in ISO-8859-1 (or Latin-1) (See note).\n",
    "\n",
    "The second then utlizes the first function to then check each author within a given record.\n",
    "\n",
    "Note: This expression is providing a few too many false positives for my liking. I'm currently working on a better expression or a different solution entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be70537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isLatinChar(text):\n",
    "    regexp = re.compile(r'(?:[^ı́\\x00-\\xff])')\n",
    "    if regexp.search(text):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def latin_script_checker(authorList):\n",
    "    try:\n",
    "        latin_scripts = [author for author in authorList if isLatinChar(author['given'])]\n",
    "        if len(latin_scripts) > 0:\n",
    "            return 1 # non-latin script found\n",
    "        else:\n",
    "            return 0 # no issue\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45d62d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['author_characters'] = df.author.map(lambda x: latin_script_checker(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8571a937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.941415178886103"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_with_non_latin = df.loc[df.author_characters == 1]\n",
    "prevalence_NonLatin = ((len(records_with_non_latin))/(len(df.author_institutions))) * 100\n",
    "prevalence_NonLatin #percentage of records with this specific issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae71cc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.313264658792253"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_missing_authors = df.loc[df.author.isnull()] # Finding all the records with null author values\n",
    "prevalence_AuMis = ((len(records_missing_authors))/(len(df.author))) * 100\n",
    "prevalence_AuMis # percentage of records with this specific issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5e3509",
   "metadata": {},
   "source": [
    "### Abstract Multi-lingualism Detection\n",
    "This function will detect the use of more than one language within the *abstract* field. As mentioned before, we're interested in how people pracitice recording metadata as it pertains to language.\n",
    "\n",
    "Here we have a list of language ISO 639-1 codes. While it is not exhaustive (there are 183 offically assigned codes, and only 94 are present in this list), it does include many of the macrolanguages for which many other languages fall within.\n",
    "\n",
    "We pass this list to `langid` to ensure a higher confidence intervals in it's identification, i.e. an abstract might be in Malay (ms) but the identifier might return 'ms' and 'id' (Indonesian) with lower confidence intervals for each. As Malay is the macrolanguage that covers Indonesian, we will keep 'ms' but not 'id'.\n",
    "\n",
    "The first `try:` block filters for records without abstracts present, then we tokenize the abstracts by sentence.\n",
    "\n",
    "Next we pick out the first sentence and the second to last sentence of each abstract. The reason for picking out the second to last sentence is because most occurences of multi-lingual abstracts are such that the abstract is first written in one language, and then a second time in another. The reason for not picking the last sentence is because it is not uncommon for footnotes or citations to be present at the end of the abstracts in these metadata records. The presence of these at the end of an abstract section make language detection problematic as the syntactical structure can be odd and leads to an incorrect detection.\n",
    "\n",
    "We then classify both sentences, followed by an evaluation of the confidence intervals. If the confidence interval is especially low, it is omitted.\n",
    "\n",
    "We then check to see if there is more than one language present in the dictionary with `len(set(lang_dict.keys()))`, if so the record is returned with a **1**, indicating and error. Otherwise it is returned with a **0**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5402f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_list = ['af', 'am', 'ar', 'as', 'az', 'be', 'bg', 'bn', 'br', \n",
    "             'bs', 'ca', 'cs', 'cy', 'da', 'de', 'dz', 'el', 'en', 'eo', \n",
    "             'es', 'et', 'eu', 'fa', 'fi', 'fo', 'fr', 'ga', 'gl', 'gu', \n",
    "             'he', 'hi', 'hr', 'ht', 'hu', 'hy', 'is', 'it', 'ja', 'jv', \n",
    "             'ka', 'kk', 'km', 'kn', 'ko', 'ku', 'ky', 'la', 'lb', 'lo', \n",
    "             'lt', 'lv', 'mg', 'mk', 'ml', 'mn', 'mr', 'ms', 'mt', 'ne', \n",
    "             'nl', 'no', 'oc', 'or', 'pa', 'pl', 'ps', 'pt', 'qu', 'ro', \n",
    "             'ru', 'rw', 'se', 'si', 'sk', 'sl', 'sq', 'sr', 'sv', 'sw', \n",
    "             'ta', 'te', 'th', 'tl', 'tr', 'ug', 'uk', 'ur', 'vi', 'vo', \n",
    "             'wa', 'xh', 'zh', 'zu']\n",
    "langid.set_languages(langs=lang_list)\n",
    "def lang_checker(abstract):\n",
    "    try:\n",
    "        # Tokenizing abstracts\n",
    "        tokenized = sent_tokenize(abstract)\n",
    "        startAndFinish = [tokenized[1], tokenized[-2]]\n",
    "        # Detecting languages present\n",
    "        lang = [langid.classify(lang) for lang in startAndFinish]\n",
    "        # Filter low confidence results\n",
    "        lang_dict = {key:value for (key,value) in lang if value > 100 or value < -100}\n",
    "        # Labeling specific issues found in record\n",
    "        if len(set(lang_dict.keys())) > 1:\n",
    "            return 1 #Multiple languages detected\n",
    "    except:\n",
    "        return None #No abstract\n",
    "    return 0 #No issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7718e37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['abstract_multi_lang']  = df.abstract.map(lambda x: lang_checker(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa50aa14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2517395200837789"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_with_MultiLang = df.loc[(df.abstract_multi_lang == 1)]\n",
    "prevalence_MultiLang = ((len(records_with_MultiLang))/(len(df.abstract_multi_lang))) * 100\n",
    "prevalence_MultiLang #returning a percent of the total number of records with this particular issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262b9517",
   "metadata": {},
   "source": [
    "### Title Language Checking\n",
    "This function will check the language of the title against the stated language of the record.\n",
    "\n",
    "It is a relatively striaghtforward function: `try:` filters out records without a *title*, then classifies the language, and finally checks to see if the returned code matches what is record in the language field.\n",
    "\n",
    "We use `df.apply` instead of `df.column.map` because of the need to check multiple fields within a record as opposed to being contained within a specific field.\n",
    "\n",
    "Here, it should be mentioned, there is some abiguity. The *language* field is not clearly defined (is it the language of the Item, Container, or the record). The prevelance of this issue (seen below) reflects the lack of clarity in what this field is meant to represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e3a1ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_lang_checker(record):\n",
    "    try:\n",
    "        lang = langid.classify(record['title'])\n",
    "        if lang[0] == record['language']:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5531c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_language'] = df.apply(title_lang_checker, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d963940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.023915254407957"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_with_TitleLang = df.loc[(df.title_language == 1)] #creating a df with only the records with these errors\n",
    "prevalence_TitleLang = ((len(records_with_TitleLang))/(len(df.title_language))) * 100\n",
    "prevalence_TitleLang #returning a percent of the total number of records with this particular issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33d03a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_dir / '03_labeled_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c86024b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
