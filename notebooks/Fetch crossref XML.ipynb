{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import time\n",
    "\n",
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm  \n",
    "from pathlib import Path\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "data_dir = Path('/Volumes/Juan/Data/crossref XML')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "indexed                   {'date-parts': [[2022, 4, 2]], 'date-time': '2...\n",
       "reference-count                                                           0\n",
       "publisher                             Japan Society for Clinical Anesthesia\n",
       "license                                                                 NaN\n",
       "content-domain               {'domain': [], 'crossmark-restriction': False}\n",
       "short-container-title                                         ['J.J.S.C.A']\n",
       "abstract                                                                NaN\n",
       "DOI                                                      10.2199/jjsca.5.84\n",
       "type                                                        journal-article\n",
       "created                   {'date-parts': [[2011, 6, 29]], 'date-time': '...\n",
       "page                                                                  84-87\n",
       "update-policy                                                           NaN\n",
       "source                                                             Crossref\n",
       "is-referenced-by-count                                                    0\n",
       "title                     ['A comparison of bupivacaine and tetracaine i...\n",
       "prefix                                                              10.2199\n",
       "volume                                                                    5\n",
       "author                    [{'given': 'Shigeru', 'family': 'FUKUI', 'sequ...\n",
       "member                                                                 1011\n",
       "published-online                                                        NaN\n",
       "container-title           ['THE JOURNAL OF JAPAN SOCIETY FOR CLINICAL AN...\n",
       "language                                                                NaN\n",
       "link                                                                    NaN\n",
       "deposited                 {'date-parts': [[2021, 5, 20]], 'date-time': '...\n",
       "score                                                                     0\n",
       "resource                  {'primary': {'URL': 'http://www.jstage.jst.go....\n",
       "issued                                             {'date-parts': [[1985]]}\n",
       "references-count                                                          0\n",
       "URL                                    http://dx.doi.org/10.2199/jjsca.5.84\n",
       "relation                                                                NaN\n",
       "ISSN                                             ['0285-4945', '1349-9149']\n",
       "issn-type                 [{'value': '0285-4945', 'type': 'print'}, {'va...\n",
       "published                                          {'date-parts': [[1985]]}\n",
       "assertion                                                               NaN\n",
       "funder                                                                  NaN\n",
       "published-print                                    {'date-parts': [[1985]]}\n",
       "reference                                                               NaN\n",
       "alternative-id                                                          NaN\n",
       "subject                                                                 NaN\n",
       "article-number                                                          NaN\n",
       "issue                                                                     1\n",
       "journal-issue             {'issue': '1', 'published-print': {'date-parts...\n",
       "subtitle                                                                NaN\n",
       "original-title                          ['Ｂｕｐｉｖａｃａｉｎｅ（ｍａｒｃａｉｎ）のせきつい麻酔への応用']\n",
       "archive                                                                 NaN\n",
       "editor                                                                  NaN\n",
       "published-other                                                         NaN\n",
       "Name: 371871, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / '01_raw_data.csv')\n",
    "df.sample().iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_read = pd.read_csv(data_dir / 'doi_file.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = list(set(id_list).difference(just_read[0].str.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 50%|█████     | 266030/530282 [24:02<12:33, 350.70it/s]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm(total=20000)\n",
    "\n",
    "new_dois = set()\n",
    "i = 0\n",
    "try:\n",
    "    with open(data_dir / 'doi_file_2.csv', 'r') as file:\n",
    "        for line in file:\n",
    "            i+=1\n",
    "            progress_bar.update(1)\n",
    "            if i < 265141:\n",
    "                continue\n",
    "            \n",
    "            # Split each line at the first comma and take the part before it\n",
    "            doi = line.split(',', 1)[0].strip().lower()\n",
    "            if doi[:3] != '10.':\n",
    "                print(doi)\n",
    "                break\n",
    "\n",
    "            new_dois.add(doi)\n",
    "\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(line)\n",
    "    raise\n",
    "            \n",
    "progress_bar.close()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_first_column(file_path):\n",
    "    column_data = []\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        for row in csvreader:\n",
    "            if row:  # Checking if the row is not empty\n",
    "                column_data.append(row[0])  # Appending the first element of each row to the list\n",
    "    return column_data\n",
    "\n",
    "def fetch_data(doi: str):\n",
    "    \"\"\"Request function to query Crossref API.\n",
    "\n",
    "    Args:\n",
    "        doi (str): The DOI of an item, used for querying Crossref API\n",
    "\n",
    "    Returns:\n",
    "        JSON: with r.status_code == 200, returns JSON response\n",
    "        None: r.status_code == 404 will return None as the resource was not found\n",
    "        function: r.status_code == 504 returns the function to retry the query\n",
    "    \"\"\"\n",
    "    base_url = 'https://doi.crossref.org/search/doi'\n",
    "    params = {'pid': 'juan@alperin.ca',\n",
    "             'format': 'unixsd',\n",
    "             'doi': doi}\n",
    "    try:\n",
    "        r = requests.get(base_url, params=params)\n",
    "        if r.status_code == 200:\n",
    "            soup = BeautifulSoup(r.content.decode('utf-8').replace('\\n', '').replace('\\r', ''), 'xml')\n",
    "            return  ''.join(str(tag) for tag in soup.find_all()).replace('\\n', '').replace('\\r', '').replace('\\t', '')\n",
    "        elif r.status_code == 404:\n",
    "            return None  \n",
    "        elif r.status_code == 504:\n",
    "            print(r.status_code)\n",
    "            time.sleep(1)\n",
    "            return fetch_data(doi)\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching DOI {doi}: {e}\")\n",
    "        return None\n",
    "    \n",
    "def get_crossref(id_list: list):\n",
    "    \"\"\"Primary function for querying Crossref API and collecting responses\n",
    "\n",
    "    Args:\n",
    "        id_list (list): List of all DOIs to be queried.\n",
    "    \"\"\"\n",
    "    chunk_size = 5000\n",
    "    tmp = []\n",
    "    \n",
    "    print(f\"Going after: {len(id_list)}.\")\n",
    "    \n",
    "    file_path = data_dir / 'doi_file.csv'\n",
    "    if file_path.is_file():\n",
    "        print(f\"The file {file_path} exists.\")\n",
    "        # cut -d',' -f1 doi_file.csv > dois_read.csv\n",
    "    else:\n",
    "        pd.DataFrame(columns=['DOI', 'message']).to_csv(file_path, mode='w', index=False)\n",
    "\n",
    "#     already_read = pd.read_csv(data_dir / 'dois_read.csv')\n",
    "#     print(f\"Already read: {len(already_read)}.\")\n",
    "#     id_list = list(set(id_list).difference(already_read.DOI.str.lower()))\n",
    "    print(f\"Going after: {len(id_list)}.\")\n",
    "        \n",
    "    # Record the starting time\n",
    "    start_time = time.time()\n",
    "    \n",
    "   \n",
    "    with tqdm(total=len(id_list)) as pbar:\n",
    "        for i, doi in enumerate(id_list):\n",
    "            try:\n",
    "                result = fetch_data(doi)\n",
    "                if result is not None:\n",
    "                    tmp.append({'DOI': doi, 'message': result})\n",
    "                    \n",
    "                if i % chunk_size == 0 or (i+1) == len(id_list):\n",
    "                    pd.DataFrame(tmp).to_csv(data_dir / 'doi_file.csv', mode='a', index=False, header=False)\n",
    "                    tmp = []\n",
    "                    end_time = time.time()\n",
    "                    if i/3 > (end_time - start_time):\n",
    "                        pause = i/3 - (end_time - start_time) \n",
    "                        print(f\"Sleeping: {int(pause)} seconds\")\n",
    "                        time.sleep(pause)\n",
    "\n",
    "                pbar.update(1)\n",
    "            except KeyboardInterrupt:\n",
    "                if len(tmp) > 1: \n",
    "                    pd.DataFrame(tmp).to_csv(data_dir / 'doi_file.csv', mode='a', index=False, header=False)                \n",
    "                raise\n",
    "            except Exception as err:                \n",
    "                print(err)\n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/106402 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going after: 106402.\n",
      "Going after: 106402.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106402/106402 [13:19:05<00:00,  2.22it/s]   \n"
     ]
    }
   ],
   "source": [
    "get_crossref(id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching data ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "x = df.sample().iloc[0]['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fetch_data('10.4138/atlgeol.2019.011')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def find_all_xml_tags(xml_string, tag_name):\n",
    "    pattern = re.compile(r'<{}([^>]*)>(.*?)</{}>'.format(tag_name, tag_name), re.DOTALL)\n",
    "    matches = re.findall(pattern, xml_string)\n",
    "    \n",
    "    tag_list = []\n",
    "    for attributes, content in matches:\n",
    "        attributes_dict = dict(re.findall(r'\\b(\\S+?)\\s*=\\s*[\\'\"](.*?)[\\'\"]', attributes))\n",
    "        tag_list.append({\n",
    "            'attributes': attributes_dict,\n",
    "            'content': content\n",
    "        })\n",
    "\n",
    "    return tag_list\n",
    "\n",
    "# Example usage\n",
    "xml_string = x\n",
    "desired_tag_name = 'jats:abstract'\n",
    "\n",
    "result = find_all_xml_tags(xml_string, desired_tag_name)\n",
    "for i, match in enumerate(result):\n",
    "    print(\"Match {}: {}\".format(i + 1, match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110498</th>\n",
       "      <td>10.1186/s13102-023-00654-y</td>\n",
       "      <td>&lt;crossref_result version=\"3.0\" xmlns=\"http://w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0  \\\n",
       "110498  10.1186/s13102-023-00654-y   \n",
       "\n",
       "                                                        1  \n",
       "110498  <crossref_result version=\"3.0\" xmlns=\"http://w...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dois = set()\n",
    "\n",
    "df = pd.read_csv(data_dir / 'outfile_5.csv', header=None)\n",
    "dois = set(df[0])\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing a:   3%|▎         | 20000/620000 [01:54<59:10, 168.97item/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found dois: 354999"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing a:   3%|▎         | 20925/620000 [02:01<1:17:00, 129.65item/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found dois: 355924"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing a:   7%|▋         | 40925/620000 [04:15<1:14:16, 129.94item/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found dois: 375924"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing a:  10%|▉         | 60925/620000 [06:29<57:11, 162.91item/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found dois: 395924"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing a:  13%|█▎        | 80925/620000 [08:15<1:02:07, 144.63item/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found dois: 410000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing a:   0%|          | 0/620000 [00:00<?, ?item/s]                \n"
     ]
    }
   ],
   "source": [
    "def list_files_with_prefix(directory, prefix):\n",
    "    file_list = [f for f in os.listdir(directory) if f.startswith(prefix) and os.path.isfile(os.path.join(directory, f))]\n",
    "    return file_list\n",
    "\n",
    "def reverse_sorted_files_by_mtime(directory, prefix):\n",
    "    file_list = list_files_with_prefix(directory, prefix)\n",
    "    file_list.sort(key=lambda x: os.path.getmtime(os.path.join(directory, x)), reverse=True)\n",
    "    return file_list\n",
    "\n",
    "# Example usage\n",
    "\n",
    "file_prefixes = ['4', '3', '2', '1', 'a']\n",
    "\n",
    "\n",
    "for file_prefix in file_prefixes: \n",
    "    clear_output(wait=True)\n",
    "    sorted_files = reverse_sorted_files_by_mtime(data_dir, \"doi_{}\".format(file_prefix))\n",
    "    # Using tqdm with a multiplier for multiple updates per iteration\n",
    "    with tqdm(total=20000*len(sorted_files), desc=\"Processing {}\".format(file_prefix), unit=\"item\") as pbar:\n",
    "        with open(data_dir / 'outfile_{}.csv'.format(file_prefix), 'a') as outfile:\n",
    "            for filename in sorted_files:\n",
    "                one_new_in_file = False\n",
    "                \n",
    "                # Your processing code goes here\n",
    "                with open(data_dir / filename, 'r') as infile:\n",
    "                    for line in infile:\n",
    "                        # Update the progress bar\n",
    "                        pbar.update(1)\n",
    "                        \n",
    "                        # Split each line at the first comma and take the part before it\n",
    "                        doi = line.split(',', 1)[0].strip().lower()\n",
    "                        if doi[:3].lower() == 'doi':\n",
    "                            continue\n",
    "                        \n",
    "                        elif doi[:3] != '10.':\n",
    "                            print(\"Something went wrong when reading: {}\".format(doi))\n",
    "                            break\n",
    "                        \n",
    "                        # skip line if we already have the DOI\n",
    "                        if doi in dois: \n",
    "                            continue\n",
    "\n",
    "                        # copy the line to a new outfile and record that we already have the DOI\n",
    "                        outfile.write(line)   \n",
    "                        dois.add(doi)                            \n",
    "                        # if we don't find any new DOIs in the whole file, stop checking\n",
    "                        # the rest of the files in this set\n",
    "                        one_new_in_file = True\n",
    "\n",
    "                # if no new DOIs found in the whole file, move onto next prefix\n",
    "                if one_new_in_file == False:\n",
    "                    break\n",
    "                tqdm.write(f\"Found dois: {len(dois)}\", end=\"\")\n",
    "                      \n",
    "        pbar.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParseError",
     "evalue": "junk after document element: line 1, column 5943 (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/Users/juan/.pyenv/versions/myenv3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3418\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-32-2524e21ea6a6>\"\u001b[0m, line \u001b[1;32m1\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    root = ET.fromstring(x)\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Users/juan/.pyenv/versions/3.8.6/lib/python3.8/xml/etree/ElementTree.py\"\u001b[0;36m, line \u001b[0;32m1320\u001b[0;36m, in \u001b[0;35mXML\u001b[0;36m\u001b[0m\n\u001b[0;31m    parser.feed(text)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32munknown\u001b[0m\n\u001b[0;31mParseError\u001b[0m\u001b[0;31m:\u001b[0m junk after document element: line 1, column 5943\n"
     ]
    }
   ],
   "source": [
    "root = ET.fromstring(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<person_name contributor_role=\"author\" sequence=\"first\"> <given_name>Mirela</given_name> <surname>Feurdean</surname> </person_name>\n",
      "<given_name>Mirela</given_name>\n",
      "<surname>Feurdean</surname>\n",
      "<person_name contributor_role=\"author\" sequence=\"additional\"> <given_name>Daniel</given_name> <surname>Matassa</surname> </person_name>\n",
      "<given_name>Daniel</given_name>\n",
      "<surname>Matassa</surname>\n",
      "<person_name contributor_role=\"author\" sequence=\"additional\"> <given_name>Mohleen</given_name> <surname>Kang</surname> </person_name>\n",
      "<given_name>Mohleen</given_name>\n",
      "<surname>Kang</surname>\n",
      "<person_name contributor_role=\"author\" sequence=\"additional\"> <given_name>Genevieve</given_name> <surname>Matthews</surname> </person_name>\n",
      "<given_name>Genevieve</given_name>\n",
      "<surname>Matthews</surname>\n",
      "<person_name contributor_role=\"author\" sequence=\"additional\"> <given_name>Neil</given_name> <surname>Kothari</surname> </person_name>\n",
      "<given_name>Neil</given_name>\n",
      "<surname>Kothari</surname>\n"
     ]
    }
   ],
   "source": [
    "for person in soup.crossref.contributors.findChildren():\n",
    "    print(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
