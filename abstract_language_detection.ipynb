{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ce21afd",
   "metadata": {},
   "source": [
    "# Detecting Multiple Languages within the Abstract field of a Metadata record\n",
    "\n",
    "Many of the high priority issue determined in phase 1 are in regard to the abstract field. \n",
    "\n",
    "This script will determine the language(s) within the abstract field and compare them against the stated language attribute of the record. To do this, the script also must ensure that those fields are present within the record.\n",
    "\n",
    "To begin, we'll import he necessary libraries and set up our generastor for iterating through the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6845651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import langid\n",
    "import pandas as pd\n",
    "import json\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Genertaor function for handling data iteration\n",
    "def gen(file_name):\n",
    "    with open(file_name, 'r') as fh:\n",
    "        for record in json.load(fh):\n",
    "            yield record\n",
    "\n",
    "# Set up dataframe for holding detected errors\n",
    "df = pd.DataFrame(columns=['DOI', 'issue'])\n",
    "data = gen('bigger_sample.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd1692f",
   "metadata": {},
   "source": [
    "Now, we have to check the records for each of these attributes, what language(s) is present in the abstract, check against the container language, and label the appropriate issue. The data here are a random sample of 1300 records from Crossref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb436d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_counter = 0\n",
    "for record in data:\n",
    "    message = record['message']\n",
    "    doi = message['DOI']\n",
    "    # Only focusing on journal articles, as to avoid false positives on\n",
    "    # types that do not normally have abstracts (e.g. books)\n",
    "    if message['type'] == 'journal-article':\n",
    "        article_counter +=1\n",
    "        try:\n",
    "            # Cleaning text by removing lxml tags\n",
    "            soup = bs(message['abstract'], features='lxml')\n",
    "            stripped_strings = soup.get_text()\n",
    "            # Tokenizing abstracts\n",
    "            tokenized = sent_tokenize(stripped_strings)\n",
    "            startAndFinish = [tokenized[1], tokenized[-2]]\n",
    "            # Detecting languages present\n",
    "            lang = [langid.classify(lang) for lang in startAndFinish]\n",
    "            # Filter low confidence results\n",
    "            lang_dict = {key:value for (key,value) in lang if value > 100 or value < -100}\n",
    "            # Labeling specific issues found in record\n",
    "            if len(set(lang_dict.keys())) > 1:\n",
    "                try:\n",
    "                    containerLanguage = message['language']\n",
    "                    if containerLanguage in lang_dict.keys():\n",
    "                        df.loc[len(df)] = [doi, 'multiple languages']\n",
    "                except:\n",
    "                    df.loc[len(df)] = [doi, 'no language attribute; multiple languages']\n",
    "            else:\n",
    "                try:\n",
    "                    containerLanguage = message['language']\n",
    "                    if containerLanguage == lang_dict.keys()[0]:\n",
    "                        df.loc[len(df)] = [doi, 'no issues found']\n",
    "                        continue\n",
    "                    else:\n",
    "                        df.loc[len(df)] = [doi, 'does not match language field']\n",
    "                        continue\n",
    "                except:\n",
    "                    df.loc[len(df)] = [doi, 'no language attribute']\n",
    "        except:\n",
    "            try:\n",
    "                languageAttribute = message['language']\n",
    "                df.loc[len(df)] = [doi, 'no abstract attribute']\n",
    "            except:\n",
    "                df.loc[len(df)] = [doi, 'no abstract attribute; no language attribute']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0342bbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "889\n"
     ]
    }
   ],
   "source": [
    "print(article_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0b0f07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503d0d81",
   "metadata": {},
   "source": [
    "We see that all of the articles in this random sample have some sort of issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09a1447e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "issue\n",
       "no abstract attribute                           629\n",
       "no language attribute                           137\n",
       "no abstract attribute; no language attribute    120\n",
       "no language attribute; multiple languages         3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts(subset=df['issue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11f0985",
   "metadata": {},
   "source": [
    "Overwhelmingly, it seems the issue is that there are fields missing from the records. Most often being the abstract field, but the absence of the language field is also very common."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
